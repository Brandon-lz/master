{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import datasets","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\n#设置log信息等级，2代表只打印重要信息\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'     ","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"%pip install tensorflow","execution_count":2,"outputs":[{"output_type":"stream","text":"Collecting tensorflow\n  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n\u001b[K     |████████████████████████████████| 394.3 MB 9.1 kB/s  eta 0:00:01    |██                              | 24.1 MB 10.0 MB/s eta 0:00:38     |████████████████▎               | 200.8 MB 18.7 MB/s eta 0:00:11     |████████████████▍               | 202.2 MB 18.7 MB/s eta 0:00:11     |███████████████████▊            | 243.7 MB 37.3 MB/s eta 0:00:05     |█████████████████████████▌      | 314.8 MB 28.4 MB/s eta 0:00:03     |███████████████████████████▌    | 338.9 MB 36.3 MB/s eta 0:00:02     |██████████████████████████████▉ | 380.4 MB 43.1 MB/s eta 0:00:01     |███████████████████████████████▊| 390.3 MB 43.1 MB/s eta 0:00:01\n\u001b[?25hCollecting gast==0.3.3\n  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\nCollecting grpcio~=1.32.0\n  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n\u001b[K     |████████████████████████████████| 3.8 MB 39.6 MB/s eta 0:00:01\n\u001b[?25hCollecting termcolor~=1.1.0\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\nCollecting h5py~=2.10.0\n  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n\u001b[K     |████████████████████████████████| 2.9 MB 51.2 MB/s eta 0:00:01\n\u001b[?25hCollecting flatbuffers~=1.12.0\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nCollecting typing-extensions~=3.7.4\n  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\nCollecting tensorboard~=2.4\n  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n\u001b[K     |████████████████████████████████| 10.6 MB 29.0 MB/s eta 0:00:01\n\u001b[?25hCollecting google-pasta~=0.2\n  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n\u001b[K     |████████████████████████████████| 57 kB 9.4 MB/s  eta 0:00:01\n\u001b[?25hCollecting wheel~=0.35\n  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\nCollecting astunparse~=1.6.3\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nCollecting opt-einsum~=3.3.0\n  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n\u001b[K     |████████████████████████████████| 65 kB 13.3 MB/s eta 0:00:01\n\u001b[?25hCollecting keras-preprocessing~=1.1.2\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[K     |████████████████████████████████| 42 kB 5.0 MB/s  eta 0:00:01\n\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0\n  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n\u001b[K     |████████████████████████████████| 462 kB 57.2 MB/s eta 0:00:01\n\u001b[?25hCollecting absl-py~=0.10\n  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n\u001b[K     |████████████████████████████████| 127 kB 34.6 MB/s eta 0:00:01\n\u001b[?25hCollecting protobuf>=3.9.2\n  Downloading protobuf-3.14.0-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n\u001b[K     |████████████████████████████████| 1.0 MB 24.3 MB/s eta 0:00:01\n\u001b[?25hCollecting wrapt~=1.12.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nRequirement already satisfied: six~=1.15.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (1.15.0)\nCollecting numpy~=1.19.2\n  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n\u001b[K     |████████████████████████████████| 14.8 MB 27.2 MB/s eta 0:00:01\n\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n\u001b[K     |████████████████████████████████| 781 kB 34.6 MB/s eta 0:00:01\n\u001b[?25hCollecting werkzeug>=0.11.15\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n\u001b[K     |████████████████████████████████| 298 kB 29.0 MB/s eta 0:00:01\n\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\nRequirement already satisfied: setuptools>=41.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (49.2.0.post20200712)\nRequirement already satisfied: requests<3,>=2.21.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\nCollecting markdown>=2.6.8\n  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n\u001b[K     |████████████████████████████████| 96 kB 10.7 MB/s eta 0:00:01\n\u001b[?25hCollecting google-auth<2,>=1.6.3\n  Downloading google_auth-1.26.1-py2.py3-none-any.whl (116 kB)\n\u001b[K     |████████████████████████████████| 116 kB 31.2 MB/s eta 0:00:01\n\u001b[?25hCollecting requests-oauthlib>=0.7.0\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.10)\nRequirement already satisfied: idna<3,>=2.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\nRequirement already satisfied: chardet<4,>=3.0.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /srv/conda/envs/notebook/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (1.7.0)\nCollecting cachetools<5.0,>=2.0.0\n  Downloading cachetools-4.2.1-py3-none-any.whl (12 kB)\nCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n\u001b[K     |████████████████████████████████| 155 kB 44.5 MB/s eta 0:00:01\n\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n  Downloading rsa-4.7-py3-none-any.whl (34 kB)\nRequirement already satisfied: oauthlib>=3.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.0.1)\nRequirement already satisfied: zipp>=0.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.1.0)\nCollecting pyasn1<0.5.0,>=0.4.6\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n\u001b[K     |████████████████████████████████| 77 kB 8.9 MB/s  eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: termcolor, wrapt\n  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=f241cebb0a3450a81416d28724b643cf673d8b466347ed9ca7e4494026593e2e\n  Stored in directory: /home/jovyan/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=70957 sha256=3347bc2d507de6343f649486fa92b2a5e3eedc02cfdc7e8e3b269f5c25b88423\n  Stored in directory: /home/jovyan/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\nSuccessfully built termcolor wrapt\nInstalling collected packages: gast, grpcio, termcolor, numpy, h5py, flatbuffers, typing-extensions, tensorboard-plugin-wit, werkzeug, wheel, requests-oauthlib, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, google-auth-oauthlib, markdown, absl-py, protobuf, tensorboard, google-pasta, astunparse, opt-einsum, keras-preprocessing, tensorflow-estimator, wrapt, tensorflow\n  Attempting uninstall: wheel\n    Found existing installation: wheel 0.34.2\n    Uninstalling wheel-0.34.2:\n      Successfully uninstalled wheel-0.34.2\nSuccessfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.1 flatbuffers-1.12 gast-0.3.3 google-auth-1.26.1 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.3.3 numpy-1.19.5 opt-einsum-3.3.0 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 werkzeug-1.0.1 wheel-0.36.2 wrapt-1.12.1\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 准备数据"},{"metadata":{"trusted":true},"cell_type":"code","source":"#加载mnist数据集，如果本地没有数据缓存，则会从网络中下载数据\n# x: [60k,28,28]\n# y: [60k]\n(x,y),_ = datasets.mnist.load_data()","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#将数据集转化为tensor格式\nx = tf.convert_to_tensor(x,dtype=tf.float32)/255.      #/255.是将数据转化为0-1.之间\ny = tf.convert_to_tensor(y,dtype=tf.int32)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape, y.shape, x.dtype, y.dtype","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"(TensorShape([60000, 28, 28]), TensorShape([60000]), tf.float32, tf.int32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#查看x数据集中的最大值与最小值\ntf.reduce_max(x),tf.reduce_min(x)","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"(<tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n <tf.Tensor: shape=(), dtype=float32, numpy=0.0>)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.reduce_max(y),tf.reduce_min(y)","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"(<tf.Tensor: shape=(), dtype=int32, numpy=9>,\n <tf.Tensor: shape=(), dtype=int32, numpy=0>)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 创建数据集"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_db = tf.data.Dataset.from_tensor_slices((x,y)).batch(128)       #将数据集按128个单位长度进行分割","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_iter = iter(train_db)     #转化为生成器\nsample = next(train_iter)\nsample[0].shape,sample[1].shape     #这里可以看到batch的作用是吧x,y数据集按128一个单位进行分割","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"(TensorShape([128, 28, 28]), TensorShape([128]))"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 权值设定\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#[b,784]=> [b,256] => [b,128] =>[b,10]\n#那么，w和b的矩阵大小需要满足矩阵相乘的规律\n#tf.Variable 类型的数据可以支持自动求导\nw1 = tf.Variable(tf.random.truncated_normal([784,256],stddev=0.1))       #重要！！默认方差为1，这里我们给一个比较小的数，效果会比较好\nb1 = tf.Variable(tf.zeros([256]))\nw2 = tf.Variable(tf.random.truncated_normal([256,128],stddev=0.1))\nb2 = tf.Variable(tf.zeros([128]))\nw3 = tf.Variable(tf.random.truncated_normal([128,10],stddev=0.1))\nb3 = tf.Variable(tf.zeros([10]))","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 1e-3\n\nfor epoc in range(10):    #设置重复次数10次，可以修改此参数进行对比，每一次都是完整的数据集迭代\n\n    #对数据集进行迭代\n    for step,(x,y) in enumerate(train_db):         #step代表循环次数，（x,y）每次从train_db中迭代出一对值\n        #x：[128,28,28]\n        #y:[128]\n        x = tf.reshape(x,[-1,28*28])\n        #print(x.shape)\n\n        with tf.GradientTape() as tape:\n\n            #x:[b,28*28]\n            #h1 = x@w1 + b1\n            #[b,784]@[784,256] + [256] = [b,256]\n            h1 = x@w1 + b1\n            h1 = tf.nn.relu(h1)   #非线性函数，去掉负数\n\n            #[b,256]@[256,128]+[128] = [b,128]\n            h2 = h1@w2 + b2\n            h2 = tf.nn.relu(h2)\n\n            #[b,128]@[128,10] = [b,10]\n            out = h2@w3 + b3\n\n\n            #compute loss\n            y_onehot = tf.one_hot(y,depth=10)     #编码\n\n            #mse = mean((y-out)^2)    计算方差\n            loss = tf.square(y_onehot - out)\n\n            #mean:scalar\n            loss = tf.reduce_mean(loss)\n\n        #梯度计算，对[w1,b1,w2,b2,w3,b3]进行求导\n        grads = tape.gradient(loss,[w1,b1,w2,b2,w3,b3])\n\n        #迭代参数，梯度下降法\n        #w1 = w1 - lr * w1_grad\n\n        '''\n        应该是这样写的，但是tensorflow中会将更新后的w1等变量恢复为tensor数据类型，后面又会报错\n        w1 = w1-lr*grads[0]\n        b1 = b1-lr*grads[1]\n        w2 = w2-lr*grads[2]\n        b2 = b2-lr*grads[3]\n        w3 = w3-lr*grads[4]\n        b3 = b3-lr*grads[5]\n        '''\n        #取而代之是这样的写法：\n        w1.assign_sub(lr*grads[0])\n        b1.assign_sub(lr*grads[1])\n        w2.assign_sub(lr*grads[2])\n        b2.assign_sub(lr*grads[3])\n        w3.assign_sub(lr*grads[4])\n        b3.assign_sub(lr*grads[5])\n\n\n\n        if step%100 == 0:       \n            print(epoc,step,'loss:',float(loss))         #每100步打印一下loss","execution_count":33,"outputs":[{"output_type":"stream","text":"0 loss: 0.14193741977214813\n100 loss: 0.1337687224149704\n200 loss: 0.1409338265657425\n300 loss: 0.12876813113689423\n400 loss: 0.14227911829948425\n0 loss: 0.12532471120357513\n100 loss: 0.11962936073541641\n200 loss: 0.12632541358470917\n300 loss: 0.11668512970209122\n400 loss: 0.1281130313873291\n0 loss: 0.11361910402774811\n100 loss: 0.10970083624124527\n200 loss: 0.11579221487045288\n300 loss: 0.10784342139959335\n400 loss: 0.11777029186487198\n0 loss: 0.10497782379388809\n100 loss: 0.10239370167255402\n200 loss: 0.10784158855676651\n300 loss: 0.10108939558267593\n400 loss: 0.10994835942983627\n0 loss: 0.09825114905834198\n100 loss: 0.09680360555648804\n200 loss: 0.10157676041126251\n300 loss: 0.09570697695016861\n400 loss: 0.10373721271753311\n0 loss: 0.09273962676525116\n100 loss: 0.09238149970769882\n200 loss: 0.0964723452925682\n300 loss: 0.09128493070602417\n400 loss: 0.09863805770874023\n0 loss: 0.08822038024663925\n100 loss: 0.0887659564614296\n200 loss: 0.09217873960733414\n300 loss: 0.08761563897132874\n400 loss: 0.09438344836235046\n0 loss: 0.08441619575023651\n100 loss: 0.08574195206165314\n200 loss: 0.08854620903730392\n300 loss: 0.08447602391242981\n400 loss: 0.09075810015201569\n0 loss: 0.08117125928401947\n100 loss: 0.08316053450107574\n200 loss: 0.08539131283760071\n300 loss: 0.08171617239713669\n400 loss: 0.08760800212621689\n0 loss: 0.0783432349562645\n100 loss: 0.08089008182287216\n200 loss: 0.08261916786432266\n300 loss: 0.07927940785884857\n400 loss: 0.08486742526292801\n","name":"stdout"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import datasets","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\n#设置log信息等级，2代表只打印重要信息\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'     ","execution_count":4,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"%pip install tensorflow","execution_count":2,"outputs":[{"output_type":"stream","text":"Collecting tensorflow\n  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n\u001b[K     |████████████████████████████████| 394.3 MB 29 kB/s s eta 0:00:01     |████████▏                       | 100.3 MB 39.3 MB/s eta 0:00:08     |██████████▋                     | 131.1 MB 26.8 MB/s eta 0:00:10     |██████████████████▎             | 224.8 MB 35.2 MB/s eta 0:00:05     |███████████████████             | 232.9 MB 35.2 MB/s eta 0:00:05     |████████████████████            | 246.1 MB 34.4 MB/s eta 0:00:05     |█████████████████████▏          | 261.3 MB 34.4 MB/s eta 0:00:04     |█████████████████████▍          | 263.3 MB 34.4 MB/s eta 0:00:04\n\u001b[?25hCollecting wheel~=0.35\n  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\nCollecting typing-extensions~=3.7.4\n  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\nCollecting protobuf>=3.9.2\n  Downloading protobuf-3.14.0-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n\u001b[K     |████████████████████████████████| 1.0 MB 12.4 MB/s eta 0:00:01\n\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0\n  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n\u001b[K     |████████████████████████████████| 462 kB 30.6 MB/s eta 0:00:01\n\u001b[?25hCollecting h5py~=2.10.0\n  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n\u001b[K     |████████████████████████████████| 2.9 MB 28.6 MB/s eta 0:00:01\n\u001b[?25hCollecting google-pasta~=0.2\n  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n\u001b[K     |████████████████████████████████| 57 kB 5.8 MB/s  eta 0:00:01\n\u001b[?25hCollecting tensorboard~=2.4\n  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n\u001b[K     |████████████████████████████████| 10.6 MB 27.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: six~=1.15.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorflow) (1.15.0)\nCollecting astunparse~=1.6.3\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nCollecting grpcio~=1.32.0\n  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n\u001b[K     |████████████████████████████████| 3.8 MB 26.1 MB/s eta 0:00:01\n\u001b[?25hCollecting termcolor~=1.1.0\n  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\nCollecting flatbuffers~=1.12.0\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nCollecting numpy~=1.19.2\n  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n\u001b[K     |████████████████████████████████| 14.8 MB 45 kB/s eta 0:00:01     |██▌                             | 1.2 MB 45 kB/s eta 0:05:03\n\u001b[?25hCollecting keras-preprocessing~=1.1.2\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[K     |████████████████████████████████| 42 kB 2.7 MB/s  eta 0:00:01\n\u001b[?25hCollecting wrapt~=1.12.1\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting absl-py~=0.10\n  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n\u001b[K     |████████████████████████████████| 127 kB 29.5 MB/s eta 0:00:01\n\u001b[?25hCollecting opt-einsum~=3.3.0\n  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n\u001b[K     |████████████████████████████████| 65 kB 6.5 MB/s  eta 0:00:01\n\u001b[?25hCollecting gast==0.3.3\n  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\nRequirement already satisfied: setuptools>=41.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (49.2.0.post20200712)\nRequirement already satisfied: requests<3,>=2.21.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\nCollecting google-auth<2,>=1.6.3\n  Downloading google_auth-1.26.1-py2.py3-none-any.whl (116 kB)\n\u001b[K     |████████████████████████████████| 116 kB 35.3 MB/s eta 0:00:01\n\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\nCollecting werkzeug>=0.11.15\n  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n\u001b[K     |████████████████████████████████| 298 kB 28.1 MB/s eta 0:00:01\n\u001b[?25hCollecting markdown>=2.6.8\n  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n\u001b[K     |████████████████████████████████| 96 kB 14.1 MB/s eta 0:00:01\n\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n\u001b[K     |████████████████████████████████| 781 kB 15.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.10)\nRequirement already satisfied: chardet<4,>=3.0.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\nCollecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n  Downloading rsa-4.7-py3-none-any.whl (34 kB)\nCollecting cachetools<5.0,>=2.0.0\n  Downloading cachetools-4.2.1-py3-none-any.whl (12 kB)\nCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n\u001b[K     |████████████████████████████████| 155 kB 27.4 MB/s eta 0:00:01\n\u001b[?25hCollecting requests-oauthlib>=0.7.0\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\nRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /srv/conda/envs/notebook/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (1.7.0)\nCollecting pyasn1>=0.1.3\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n\u001b[K     |████████████████████████████████| 77 kB 7.7 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.0.1)\nRequirement already satisfied: zipp>=0.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.1.0)\nBuilding wheels for collected packages: termcolor, wrapt\n  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=29f0809f7bd8e930105ec8e1878fa529ecb5a0dcd34f6006f84d1bedb4733081\n  Stored in directory: /home/jovyan/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=70969 sha256=87b0836a5bd12130cc497702874d0f55bca4c9ad5f313c675802674191f5c431\n  Stored in directory: /home/jovyan/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\nSuccessfully built termcolor wrapt\nInstalling collected packages: wheel, typing-extensions, protobuf, tensorflow-estimator, numpy, h5py, google-pasta, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, requests-oauthlib, google-auth-oauthlib, werkzeug, markdown, tensorboard-plugin-wit, grpcio, absl-py, tensorboard, astunparse, termcolor, flatbuffers, keras-preprocessing, wrapt, opt-einsum, gast, tensorflow\n  Attempting uninstall: wheel\n    Found existing installation: wheel 0.34.2\n    Uninstalling wheel-0.34.2:\n      Successfully uninstalled wheel-0.34.2\nSuccessfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.1 flatbuffers-1.12 gast-0.3.3 google-auth-1.26.1 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.3.3 numpy-1.19.5 opt-einsum-3.3.0 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 werkzeug-1.0.1 wheel-0.36.2 wrapt-1.12.1\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 准备数据"},{"metadata":{"trusted":true},"cell_type":"code","source":"#加载mnist数据集，如果本地没有数据缓存，则会从网络中下载数据\n# x: [60k,28,28]\n# y: [60k]\n(x,y),_ = datasets.mnist.load_data()","execution_count":5,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11493376/11490434 [==============================] - 1s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#将数据集转化为tensor格式\nx = tf.convert_to_tensor(x,dtype=tf.float32)/255.      #/255.是将数据转化为0-1.之间\ny = tf.convert_to_tensor(y,dtype=tf.int32)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape, y.shape, x.dtype, y.dtype","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"(TensorShape([60000, 28, 28]), TensorShape([60000]), tf.float32, tf.int32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#查看x数据集中的最大值与最小值\ntf.reduce_max(x),tf.reduce_min(x)","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"(<tf.Tensor: shape=(), dtype=float32, numpy=1.0>,\n <tf.Tensor: shape=(), dtype=float32, numpy=0.0>)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.reduce_max(y),tf.reduce_min(y)","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"(<tf.Tensor: shape=(), dtype=int32, numpy=9>,\n <tf.Tensor: shape=(), dtype=int32, numpy=0>)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 创建数据集"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_db = tf.data.Dataset.from_tensor_slices((x,y)).batch(128)       #将数据集按128个单位长度进行分割","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_iter = iter(train_db)     #转化为生成器\nsample = next(train_iter)\nsample[0].shape,sample[1].shape     #这里可以看到batch的作用是吧x,y数据集按128一个单位进行分割","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"(TensorShape([128, 28, 28]), TensorShape([128]))"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 权值设定\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#[b,784]=> [b,256] => [b,128] =>[b,10]\n#那么，w和b的矩阵大小需要满足矩阵相乘的规律\n#tf.Variable 类型的数据可以支持自动求导\nw1 = tf.Variable(tf.random.truncated_normal([784,256],stddev=0.1))       #重要！！默认方差为1，这里我们给一个比较小的数，效果会比较好\nb1 = tf.Variable(tf.zeros([256]))\nw2 = tf.Variable(tf.random.truncated_normal([256,128],stddev=0.1))\nb2 = tf.Variable(tf.zeros([128]))\nw3 = tf.Variable(tf.random.truncated_normal([128,10],stddev=0.1))\nb3 = tf.Variable(tf.zeros([10]))","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 1e-3\n\nfor epoc in range(10):    #设置重复次数10次，可以修改此参数进行对比，每一次都是完整的数据集迭代\n\n    #对数据集进行迭代\n    for step,(x,y) in enumerate(train_db):         #step代表循环次数，（x,y）每次从train_db中迭代出一对值\n        #x：[128,28,28]\n        #y:[128]\n        x = tf.reshape(x,[-1,28*28])\n        #print(x.shape)\n\n        with tf.GradientTape() as tape:\n\n            #x:[b,28*28]\n            #h1 = x@w1 + b1\n            #[b,784]@[784,256] + [256] = [b,256]\n            h1 = x@w1 + b1\n            h1 = tf.nn.relu(h1)   #非线性函数，去掉负数\n\n            #[b,256]@[256,128]+[128] = [b,128]\n            h2 = h1@w2 + b2\n            h2 = tf.nn.relu(h2)\n\n            #[b,128]@[128,10] = [b,10]\n            out = h2@w3 + b3\n\n\n            #compute loss\n            y_onehot = tf.one_hot(y,depth=10)     #编码\n\n            #mse = mean((y-out)^2)    计算方差\n            loss = tf.square(y_onehot - out)\n\n            #mean:scalar\n            loss = tf.reduce_mean(loss)\n\n        #梯度计算，对[w1,b1,w2,b2,w3,b3]进行求导\n        grads = tape.gradient(loss,[w1,b1,w2,b2,w3,b3])\n\n        #迭代参数，梯度下降法\n        #w1 = w1 - lr * w1_grad\n\n        '''\n        应该是这样写的，但是tensorflow中会将更新后的w1等变量恢复为tensor数据类型，后面又会报错\n        w1 = w1-lr*grads[0]\n        b1 = b1-lr*grads[1]\n        w2 = w2-lr*grads[2]\n        b2 = b2-lr*grads[3]\n        w3 = w3-lr*grads[4]\n        b3 = b3-lr*grads[5]\n        '''\n        #取而代之是这样的写法：\n        w1.assign_sub(lr*grads[0])\n        b1.assign_sub(lr*grads[1])\n        w2.assign_sub(lr*grads[2])\n        b2.assign_sub(lr*grads[3])\n        w3.assign_sub(lr*grads[4])\n        b3.assign_sub(lr*grads[5])\n\n\n\n        if step%100 == 0:       \n            print(epoc,step,'loss:',float(loss))         #每100步打印一下loss，并打印循环的次序","execution_count":13,"outputs":[{"output_type":"stream","text":"0 0 loss: 0.3397562503814697\n0 100 loss: 0.19157014787197113\n0 200 loss: 0.16938775777816772\n0 300 loss: 0.16239294409751892\n0 400 loss: 0.1708572804927826\n1 0 loss: 0.15272292494773865\n1 100 loss: 0.14506745338439941\n1 200 loss: 0.13942284882068634\n1 300 loss: 0.13654910027980804\n1 400 loss: 0.14457686245441437\n2 0 loss: 0.1313253790140152\n2 100 loss: 0.12739227712154388\n2 200 loss: 0.1224694699048996\n2 300 loss: 0.12120924890041351\n2 400 loss: 0.12830333411693573\n3 0 loss: 0.11726796627044678\n3 100 loss: 0.11568419635295868\n3 200 loss: 0.11096692085266113\n3 300 loss: 0.11068177223205566\n3 400 loss: 0.11736283451318741\n4 0 loss: 0.10735545307397842\n4 100 loss: 0.10733451694250107\n4 200 loss: 0.10264060646295547\n4 300 loss: 0.10304568707942963\n4 400 loss: 0.10956726223230362\n5 0 loss: 0.10005934536457062\n5 100 loss: 0.10104074329137802\n5 200 loss: 0.0962456613779068\n5 300 loss: 0.09723677486181259\n5 400 loss: 0.10365629196166992\n6 0 loss: 0.09443774074316025\n6 100 loss: 0.09605032205581665\n6 200 loss: 0.0911651998758316\n6 300 loss: 0.09260954707860947\n6 400 loss: 0.09893284738063812\n7 0 loss: 0.08989178389310837\n7 100 loss: 0.09199634939432144\n7 200 loss: 0.08703938871622086\n7 300 loss: 0.08882665634155273\n7 400 loss: 0.09505019336938858\n8 0 loss: 0.08614029735326767\n8 100 loss: 0.08863107115030289\n8 200 loss: 0.08361302316188812\n8 300 loss: 0.08569248765707016\n8 400 loss: 0.09184228628873825\n9 0 loss: 0.08296196162700653\n9 100 loss: 0.08580043911933899\n9 200 loss: 0.08071242272853851\n9 300 loss: 0.08300004154443741\n9 400 loss: 0.08912558108568192\n","name":"stdout"}]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"张量限幅.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMISOKyz5sospvcAcQdsiBx"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"clp14oDfthf1"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8lo1Ftdguw0g"},"source":["### clip_by_value  设置张量限幅\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pcg2e5hIttGC","executionInfo":{"status":"ok","timestamp":1613545784649,"user_tz":-480,"elapsed":785,"user":{"displayName":"刘昭","photoUrl":"","userId":"05952102259621678135"}},"outputId":"010d309f-4ad7-4273-bd53-8fc97576b583"},"source":["a = tf.range(10)\r\n","a"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nkS_CuzAuoXy","executionInfo":{"status":"ok","timestamp":1613545616211,"user_tz":-480,"elapsed":802,"user":{"displayName":"刘昭","photoUrl":"","userId":"05952102259621678135"}},"outputId":"ec56b576-6de0-4e22-b55b-4902710628c7"},"source":["tf.maximum(a,3)      #限制下限幅"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(10,), dtype=int32, numpy=array([3, 3, 3, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FFvYzqaQzHCQ","executionInfo":{"status":"ok","timestamp":1613545689115,"user_tz":-480,"elapsed":774,"user":{"displayName":"刘昭","photoUrl":"","userId":"05952102259621678135"}},"outputId":"95cac1b9-ae3c-4b4c-a6b3-647c10bd892e"},"source":["tf.minimum(a,8)      #限制上限幅"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 8], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e2z4gUQj0Qz_","executionInfo":{"status":"ok","timestamp":1613545685269,"user_tz":-480,"elapsed":765,"user":{"displayName":"刘昭","photoUrl":"","userId":"05952102259621678135"}},"outputId":"c4e235f6-2416-4ffb-b9f0-a6d591d572fc"},"source":["tf.clip_by_value(a,3,8)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(10,), dtype=int32, numpy=array([3, 3, 3, 3, 4, 5, 6, 7, 8, 8], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"1dWvbYge0kA5"},"source":["### relu"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FVFtCF-V0T3t","executionInfo":{"status":"ok","timestamp":1613545787289,"user_tz":-480,"elapsed":788,"user":{"displayName":"刘昭","photoUrl":"","userId":"05952102259621678135"}},"outputId":"644cbc71-50b1-4599-bb09-56cd9aa0b049"},"source":["a = a-5\r\n","a"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(10,), dtype=int32, numpy=array([-5, -4, -3, -2, -1,  0,  1,  2,  3,  4], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UwLJX7IP0oys","executionInfo":{"status":"ok","timestamp":1613545813614,"user_tz":-480,"elapsed":755,"user":{"displayName":"刘昭","photoUrl":"","userId":"05952102259621678135"}},"outputId":"39e8bf71-0366-4f21-a01e-01709287f75c"},"source":["tf.nn.relu(a)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 0, 1, 2, 3, 4], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qk2RY1gv0zNJ","executionInfo":{"status":"ok","timestamp":1613545834320,"user_tz":-480,"elapsed":749,"user":{"displayName":"刘昭","photoUrl":"","userId":"05952102259621678135"}},"outputId":"19fd0a5f-1549-488e-da6b-b87718dbe2ec"},"source":["tf.maximum(a,0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 0, 1, 2, 3, 4], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"C4d7T0641VlS"},"source":["### clip_by_norm 范数限幅"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WiBcxd_404Q6","executionInfo":{"status":"ok","timestamp":1613545864852,"user_tz":-480,"elapsed":785,"user":{"displayName":"刘昭","photoUrl":"","userId":"05952102259621678135"}},"outputId":"0d7daea7-92ff-4fac-f472-41bcd45f85d7"},"source":["a = tf.random.normal([2,2],mean=10)\r\n","a"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[10.06273 ,  8.777875],\n","       [ 8.819092, 10.545747]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TAOcbBnh0-mR","executionInfo":{"status":"ok","timestamp":1613545874834,"user_tz":-480,"elapsed":777,"user":{"displayName":"刘昭","photoUrl":"","userId":"05952102259621678135"}},"outputId":"93f26069-522d-4e18-9dc9-98a8dff2148c"},"source":["tf.norm(a)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=19.165041>"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tHfwqz511CHp","executionInfo":{"status":"ok","timestamp":1613545898451,"user_tz":-480,"elapsed":506,"user":{"displayName":"刘昭","photoUrl":"","userId":"05952102259621678135"}},"outputId":"83513f62-cb26-4b2a-84ff-38f7e406fe82"},"source":["#将a的范数（模长）放缩为15\r\n","aa = tf.clip_by_norm(a,15)     \r\n","aa"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[7.875848 , 6.870224 ],\n","       [6.9024835, 8.253893 ]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Frr3VEZk1Gi4","executionInfo":{"status":"ok","timestamp":1613546003054,"user_tz":-480,"elapsed":851,"user":{"displayName":"刘昭","photoUrl":"","userId":"05952102259621678135"}},"outputId":"a6eaff04-db51-4b95-a97d-461a0ba12ff6"},"source":["tf.norm(aa)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=14.999999>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"OrjMnIHZ1zIb"},"source":["### Gradient clipping  梯度限幅"]},{"cell_type":"markdown","metadata":{"id":"F9O4WAaa6BVU"},"source":["### gradient exploding or vanishing  对于梯度爆炸或梯度消失，需要对梯度进行限幅\r\n","梯度爆炸会导致优化的时候参数来回震荡，而梯度消失会导致参数优化起来非常吃力\r\n","\r\n","set lr=1   设置过小或过大都有可能发生梯度爆炸或梯度消失\r\n","\r\n","new_grads, total_norm = tf.clip_by_global_norm(grads,25)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AoqAvKmq1hVp","outputId":"1f11d479-470f-4902-c498-4ec51993fb90"},"source":["import  tensorflow as tf\r\n","from    tensorflow import keras\r\n","from    tensorflow.keras import datasets, layers, optimizers\r\n","import  os\r\n","\r\n","os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\r\n","print(tf.__version__)\r\n","\r\n","(x, y), _ = datasets.mnist.load_data()\r\n","x = tf.convert_to_tensor(x, dtype=tf.float32) / 50.\r\n","y = tf.convert_to_tensor(y)\r\n","y = tf.one_hot(y, depth=10)\r\n","print('x:', x.shape, 'y:', y.shape)\r\n","train_db = tf.data.Dataset.from_tensor_slices((x,y)).batch(128).repeat(30)\r\n","x,y = next(iter(train_db))\r\n","print('sample:', x.shape, y.shape)\r\n","# print(x[0], y[0])\r\n","\r\n","\r\n","\r\n","def main():\r\n","\r\n","  # 784 => 512\r\n","  w1, b1 = tf.Variable(tf.random.truncated_normal([784, 512], stddev=0.1)), tf.Variable(tf.zeros([512]))\r\n","  # 512 => 256\r\n","  w2, b2 = tf.Variable(tf.random.truncated_normal([512, 256], stddev=0.1)), tf.Variable(tf.zeros([256]))\r\n","  # 256 => 10\r\n","  w3, b3 = tf.Variable(tf.random.truncated_normal([256, 10], stddev=0.1)), tf.Variable(tf.zeros([10]))\r\n","\r\n","\r\n","\r\n","  optimizer = optimizers.SGD(lr=0.01)\r\n","\r\n","\r\n","  for step, (x,y) in enumerate(train_db):\r\n","\r\n","    # [b, 28, 28] => [b, 784]\r\n","    x = tf.reshape(x, (-1, 784))\r\n","\r\n","    with tf.GradientTape() as tape:\r\n","\r\n","      # layer1.\r\n","      h1 = x @ w1 + b1\r\n","      h1 = tf.nn.relu(h1)\r\n","      # layer2\r\n","      h2 = h1 @ w2 + b2\r\n","      h2 = tf.nn.relu(h2)\r\n","      # output\r\n","      out = h2 @ w3 + b3\r\n","      # out = tf.nn.relu(out)\r\n","\r\n","      # compute loss\r\n","      # [b, 10] - [b, 10]\r\n","      loss = tf.square(y-out)\r\n","      # [b, 10] => [b]\r\n","      loss = tf.reduce_mean(loss, axis=1)\r\n","      # [b] => scalar\r\n","      loss = tf.reduce_mean(loss)\r\n","\r\n","\r\n","\r\n","    #compute gradient\r\n","    grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\r\n","    #print('==before==')\r\n","    #for g in grads:\r\n","    #  print(tf.norm(g))\r\n","    \r\n","    grads,  _ = tf.clip_by_global_norm(grads, 15)    #！！通过clipping操作可以非常明显的对学习过程进行优化\r\n","\r\n","    #print('==after==')\r\n","    #for g in grads:\r\n","    #  print(tf.norm(g))\r\n","    #update w' = w - lr*grad\r\n","    optimizer.apply_gradients(zip(grads, [w1, b1, w2, b2, w3, b3]))\r\n","\r\n","\r\n","\r\n","    if step % 100 == 0:\r\n","        print(step, 'loss:', float(loss))\r\n","\r\n","\r\n","\r\n","\r\n","if __name__ == '__main__':\r\n","  main()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2.4.1\n","x: (60000, 28, 28) y: (60000, 10)\n","sample: (128, 28, 28) (128, 10)\n","0 loss: 23.39851188659668\n","100 loss: 0.5639000535011292\n","200 loss: 0.18785670399665833\n","300 loss: 0.11751298606395721\n","400 loss: 0.08844572305679321\n","500 loss: 0.08472402393817902\n","600 loss: 0.10523843765258789\n","700 loss: 0.07382898032665253\n","800 loss: 0.07729995250701904\n","900 loss: 0.06435120105743408\n","1000 loss: 0.05755949020385742\n","1100 loss: 0.06252418458461761\n","1200 loss: 0.06925288587808609\n","1300 loss: 0.06465571373701096\n","1400 loss: 0.04530062898993492\n","1500 loss: 0.05128102004528046\n","1600 loss: 0.055705830454826355\n","1700 loss: 0.05883311480283737\n","1800 loss: 0.06530734896659851\n","1900 loss: 0.05067121610045433\n","2000 loss: 0.04421452060341835\n","2100 loss: 0.047242917120456696\n","2200 loss: 0.0543193593621254\n","2300 loss: 0.04162650555372238\n","2400 loss: 0.04668658599257469\n","2500 loss: 0.047709427773952484\n","2600 loss: 0.049346525222063065\n","2700 loss: 0.05850733071565628\n","2800 loss: 0.035876981914043427\n","2900 loss: 0.03817438334226608\n","3000 loss: 0.04612124711275101\n","3100 loss: 0.033564381301403046\n","3200 loss: 0.050616126507520676\n","3300 loss: 0.03459913283586502\n","3400 loss: 0.03289087116718292\n","3500 loss: 0.042174331843853\n","3600 loss: 0.040740542113780975\n","3700 loss: 0.032768070697784424\n","3800 loss: 0.03692372515797615\n","3900 loss: 0.03899386152625084\n","4000 loss: 0.039651233702898026\n","4100 loss: 0.03420316427946091\n","4200 loss: 0.0315326452255249\n","4300 loss: 0.034981682896614075\n","4400 loss: 0.03156221657991409\n","4500 loss: 0.033055514097213745\n","4600 loss: 0.032913148403167725\n","4700 loss: 0.03826519474387169\n","4800 loss: 0.0392548143863678\n","4900 loss: 0.03184554725885391\n","5000 loss: 0.04062148183584213\n","5100 loss: 0.026098202913999557\n","5200 loss: 0.03229716792702675\n","5300 loss: 0.029483314603567123\n","5400 loss: 0.039318330585956573\n","5500 loss: 0.030931007117033005\n","5600 loss: 0.03626392036676407\n","5700 loss: 0.03335391730070114\n","5800 loss: 0.037255436182022095\n","5900 loss: 0.03704562783241272\n","6000 loss: 0.03216278553009033\n","6100 loss: 0.03459347411990166\n","6200 loss: 0.03027130663394928\n","6300 loss: 0.02841002121567726\n","6400 loss: 0.027063051238656044\n","6500 loss: 0.0252329483628273\n","6600 loss: 0.0295918807387352\n","6700 loss: 0.03518287092447281\n","6800 loss: 0.03273443877696991\n","6900 loss: 0.028660181909799576\n","7000 loss: 0.025024665519595146\n","7100 loss: 0.026883000507950783\n","7200 loss: 0.024659540504217148\n","7300 loss: 0.025343822315335274\n","7400 loss: 0.023704340681433678\n","7500 loss: 0.01987738534808159\n","7600 loss: 0.032463379204273224\n","7700 loss: 0.031413815915584564\n","7800 loss: 0.02767450362443924\n","7900 loss: 0.030671115964651108\n","8000 loss: 0.026423491537570953\n","8100 loss: 0.025480730459094048\n","8200 loss: 0.03528589755296707\n","8300 loss: 0.02613760717213154\n","8400 loss: 0.022368106991052628\n","8500 loss: 0.028657130897045135\n","8600 loss: 0.02699490636587143\n","8700 loss: 0.02767675556242466\n","8800 loss: 0.030761443078517914\n","8900 loss: 0.020611759275197983\n","9000 loss: 0.023606974631547928\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GA60YUaZ_fY7"},"source":[""],"execution_count":null,"outputs":[]}]}
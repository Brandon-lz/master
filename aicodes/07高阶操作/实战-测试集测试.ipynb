{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"实战-测试集测试.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNOZQHnr4GOYVnzdYxacLXP"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eex6l44vEwuJ","executionInfo":{"status":"ok","timestamp":1613639862593,"user_tz":-480,"elapsed":14902,"user":{"displayName":"刘昭","photoUrl":"","userId":"05952102259621678135"}},"outputId":"4ae67031-9a68-4539-f7c1-faff1afa51f4"},"source":["import  tensorflow as tf\r\n","from    tensorflow import keras\r\n","from    tensorflow.keras import datasets\r\n","import  os\r\n","\r\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\r\n","\r\n","repeat_num = 100\r\n","\r\n","# x: [60k, 28, 28], [10, 28, 28]\r\n","# y: [60k], [10k]\r\n","(x, y), (x_test, y_test) = datasets.mnist.load_data()\r\n","# x: [0~255] => [0~1.]\r\n","x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\r\n","y = tf.convert_to_tensor(y, dtype=tf.int32)\r\n","\r\n","#准备测试集\r\n","x_test = tf.convert_to_tensor(x_test, dtype=tf.float32) / 255.\r\n","y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)\r\n","\r\n","print(x.shape, y.shape, x.dtype, y.dtype)\r\n","print(tf.reduce_min(x), tf.reduce_max(x))\r\n","print(tf.reduce_min(y), tf.reduce_max(y))\r\n","\r\n","\r\n","train_db = tf.data.Dataset.from_tensor_slices((x,y)).batch(128)\r\n","test_db = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(128)\r\n","train_iter = iter(train_db)\r\n","\r\n","#查看一下每个数据的内容\r\n","sample = next(train_iter)\r\n","print('batch:', sample[0].shape, sample[1].shape)\r\n","\r\n","\r\n","# [b, 784] => [b, 256] => [b, 128] => [b, 10]\r\n","# [dim_in, dim_out], [dim_out]\r\n","w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\r\n","b1 = tf.Variable(tf.zeros([256]))\r\n","w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\r\n","b2 = tf.Variable(tf.zeros([128]))\r\n","w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\r\n","b3 = tf.Variable(tf.zeros([10]))\r\n","\r\n","lr = 1e-3     #常量，\r\n","\r\n","for epoch in range(repeat_num): # iterate db for 10\r\n","  for step, (x, y) in enumerate(train_db): # for every batch\r\n","    # x:[128, 28, 28]\r\n","    # y: [128]\r\n","\r\n","    # [b, 28, 28] => [b, 28*28]\r\n","    x = tf.reshape(x, [-1, 28*28])\r\n","    \r\n","\r\n","    with tf.GradientTape() as tape: # tf.Variable\r\n","      # x: [b, 28*28]\r\n","      # h1 = x@w1 + b1\r\n","      # [b, 784]@[784, 256] + [256] => [b, 256] + [256] => [b, 256] + [b, 256]\r\n","      h1 = x@w1 + tf.broadcast_to(b1, [x.shape[0], 256])\r\n","      h1 = tf.nn.relu(h1)\r\n","      # [b, 256] => [b, 128]\r\n","      h2 = h1@w2 + b2\r\n","      h2 = tf.nn.relu(h2)\r\n","      # [b, 128] => [b, 10]\r\n","      out = h2@w3 + b3\r\n","\r\n","      # compute loss\r\n","      # out: [b, 10]\r\n","      # y: [b] => [b, 10]\r\n","      y_onehot = tf.one_hot(y, depth=10)\r\n","\r\n","      # mse = mean(sum(y-out)^2)\r\n","      # [b, 10]\r\n","      loss = tf.square(y_onehot - out)\r\n","      # mean: scalar\r\n","      loss = tf.reduce_mean(loss)\r\n","\r\n","    # compute gradients\r\n","    grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])   #分别计算每个梯度\r\n","    # print(grads)\r\n","    # w1 = w1 - lr * w1_grad\r\n","    w1.assign_sub(lr * grads[0])\r\n","    b1.assign_sub(lr * grads[1])\r\n","    w2.assign_sub(lr * grads[2])\r\n","    b2.assign_sub(lr * grads[3])\r\n","    w3.assign_sub(lr * grads[4])\r\n","    b3.assign_sub(lr * grads[5])\r\n","\r\n","\r\n","    if step % 100 == 0:\r\n","      print(epoch, step, 'loss:', float(loss))\r\n","\r\n","\r\n","  #完成一次学习之后进行测试\r\n","  total_correct,total_num = 0,0\r\n","  for step,(x,y) in enumerate(test_db):\r\n","    #准备数据\r\n","    x = tf.reshape(x,[-1,28*28])\r\n","\r\n","    #验证数据   [b,784]=>[b,128]=>[b,10]\r\n","    h1 = tf.nn.relu(x@w1+b1)\r\n","    h2 = tf.nn.relu(h1@w2+b2)\r\n","    out = h2@w3 + b3\r\n","\r\n","    #print(type(out))\r\n","\r\n","    prob = tf.nn.softmax(out,axis=-1)    #转化为概率，这一块不太明白\r\n","    pred = tf.argmax(prob,axis=-1)    #选择概率最大的索引，即预测结果\r\n","\r\n","    correct = tf.cast(tf.equal(pred,tf.cast(y,dtype=tf.int64)),dtype=tf.int32)     #pred是int64数据\r\n","    correct = tf.reduce_sum(correct)\r\n","    total_correct += int(correct)\r\n","    total_num += x.shape[0]\r\n","  acc = total_correct/total_num\r\n","  print('acc: ',acc)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["(60000, 28, 28) (60000,) <dtype: 'float32'> <dtype: 'int32'>\n","tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n","tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)\n","batch: (128, 28, 28) (128,)\n","0 0 loss: 0.3037424683570862\n","0 100 loss: 0.1810416281223297\n","0 200 loss: 0.16564002633094788\n","0 300 loss: 0.1600383222103119\n","0 400 loss: 0.1662016063928604\n","acc:  0.1588\n","1 0 loss: 0.15770477056503296\n","1 100 loss: 0.14660820364952087\n","1 200 loss: 0.13959011435508728\n","1 300 loss: 0.13579076528549194\n","1 400 loss: 0.1403702199459076\n","acc:  0.2173\n","2 0 loss: 0.13453714549541473\n","2 100 loss: 0.13020943105220795\n","2 200 loss: 0.12370363622903824\n","2 300 loss: 0.12102456390857697\n","2 400 loss: 0.12468135356903076\n","acc:  0.2727\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ahP-M1-NH9XO"},"source":[""],"execution_count":null,"outputs":[]}]}
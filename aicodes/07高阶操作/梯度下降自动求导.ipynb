{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "梯度下降自动求导.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxDr+6Yl83pMwPqG2VRlPM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brandon-lz/master/blob/main/aicodes/07%E9%AB%98%E9%98%B6%E6%93%8D%E4%BD%9C/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r4sRJYKZtc1"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63i-YfrRdBIg"
      },
      "source": [
        "自动求导"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoBQp9CAeZ7b"
      },
      "source": [
        "一阶导数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m9AwANOZ30N",
        "outputId": "c1a1bd68-5827-4697-993a-c5c1b5555fd9"
      },
      "source": [
        "w = tf.constant(1.)\r\n",
        "x = tf.constant(2.)\r\n",
        "b = tf.constant(3.)\r\n",
        "\r\n",
        "#计算过程必须放在梯度环境下\r\n",
        "with tf.GradientTape() as tape:\r\n",
        "  tape.watch([w])         #设置求导对象\r\n",
        "  y = x*w           #方程式\r\n",
        "\r\n",
        "grad2 = tape.gradient(y,[w])      #自动求导，表示y对w的导数,这里默认只能调用一次，然后释放掉相关的资源以节省内存\r\n",
        "grad2                   #如果想不释放，可以用tf.GradientTape(persistent=True)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=2.0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph3ciso1eeJK"
      },
      "source": [
        "二阶求导"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGkXEKdMcmGD",
        "outputId": "2903d504-ccbd-433e-b3c4-ea346c7b620f"
      },
      "source": [
        "w = tf.constant(1.)\r\n",
        "x = tf.constant(2.)\r\n",
        "b = tf.constant(3.)\r\n",
        "\r\n",
        "with tf.GradientTape() as t1:\r\n",
        "  with tf.GradientTape() as t2:\r\n",
        "    t2.watch([w,b])\r\n",
        "    y = x * w + b\r\n",
        "  dy_dw,dy_db = t2.gradient(y,[w,b])\r\n",
        "  print(dy_dw,dy_db)\r\n",
        "d2y_dw2 = t1.gradient(dy_dw,w)\r\n",
        "print(d2y_dw2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(2.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4R0rcR3fCEP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
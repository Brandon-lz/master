{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FashionMNIST实战 .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8B/ieCz/6N8f883TWakNf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brandon-lz/master/blob/main/aicodes/11%E5%88%9D%E6%AC%A1%E5%AE%9E%E6%88%98/FashionMNIST%E5%AE%9E%E6%88%98_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFpK7DL6vPpp"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import  keras\r\n",
        "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STmhK6kPvf6H",
        "outputId": "39a297d5-ff60-429b-f639-effacf04c7f6"
      },
      "source": [
        "(x,y), (x_test,y_test) = datasets.fashion_mnist.load_data()\r\n",
        "print(x.shape,y.shape,x.max())    #与mnist数据大小相同"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,) 255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmFdYBT6wNtB"
      },
      "source": [
        "def preprocess(x,y):\r\n",
        "  x = tf.cast(x,dtype=tf.float32)/255.\r\n",
        "  y = tf.cast(y,dtype=tf.int32)\r\n",
        "  return x,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAiRN5kXwAX-",
        "outputId": "a6acf23f-c717-482d-edc0-eab7d7ccdb59"
      },
      "source": [
        "batchsz = 128\r\n",
        "db = tf.data.Dataset.from_tensor_slices((x,y))\r\n",
        "db = db.map(preprocess).shuffle(10000).batch(batchsz)\r\n",
        "\r\n",
        "db_test = tf.data.Dataset.from_tensor_slices((x_test,y_test))\r\n",
        "db_test = db_test.map(preprocess).shuffle(10000).batch(batchsz)\r\n",
        "\r\n",
        "db_iter = iter(db)\r\n",
        "sample = next(db_iter)\r\n",
        "print(sample[0].shape,sample[1].shape)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 28, 28) (128,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZMBd0OMxctl",
        "outputId": "dfa6a0af-f29a-4abb-e52c-375f93ba2a52"
      },
      "source": [
        "#创建神经网络层，共五层\r\n",
        "model = Sequential([\r\n",
        "    layers.Dense(256,activation=tf.nn.relu),     #[b,784] => [b,256]     初始层\r\n",
        "    layers.Dense(128,activation=tf.nn.relu),     #[b,256] => [b,128]     中间层...\r\n",
        "    layers.Dense(64,activation=tf.nn.relu),     #[b,128] => [b,64]     \r\n",
        "    layers.Dense(32,activation=tf.nn.relu),     #[b,64] => [b,32]           \r\n",
        "    layers.Dense(10,activation=tf.nn.relu),     #[b,32] => [b,10]       输出层\r\n",
        "                                #最后一层的参数量330 = 32*10 + 10\r\n",
        "])\r\n",
        "\r\n",
        "model.build(input_shape=[None,28*28])\r\n",
        "model.summary()   #打印网络结构"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 244,522\n",
            "Trainable params: 244,522\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAr8-wJB0cS2"
      },
      "source": [
        "optimizer = optimizers.Adam(lr=1e-3)    #创建优化器"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaFVZqKyyyYs",
        "outputId": "91ba5860-d8e0-4253-b075-4304265c4a0e"
      },
      "source": [
        "def main():\r\n",
        "  for epoch in range(30):\r\n",
        "    for step,(x,y) in enumerate(db):\r\n",
        "      x = tf.reshape(x,[-1,28*28])\r\n",
        "\r\n",
        "      with tf.GradientTape() as tape:\r\n",
        "        logits = model(x)\r\n",
        "        y_onehot = tf.one_hot(y,depth=10)\r\n",
        "        loss_mse = tf.reduce_mean(tf.losses.MSE(y_onehot,logits))     #MSE\r\n",
        "        loss_ce = tf.losses.categorical_crossentropy(y_onehot,logits,from_logits=True)   #交叉熵\r\n",
        "        loss_ce = tf.reduce_mean(loss_ce)\r\n",
        "      grads = tape.gradient(loss_ce,model.trainable_variables)      #根据loss求梯度\r\n",
        "      optimizer.apply_gradients(zip(grads,model.trainable_variables))    #更新参数，优化过程（w = w - lr*grads）\r\n",
        "\r\n",
        "      if step%100==0 :\r\n",
        "        print(epoch,step,'loss=',float(loss_ce))\r\n",
        "\r\n",
        "    #test调试\r\n",
        "    total_correct=0\r\n",
        "    total_num=0\r\n",
        "    for x,y in db_test:\r\n",
        "      x = tf.reshape(x,[-1,28*28])\r\n",
        "      logits = model(x)\r\n",
        "      prob = tf.nn.softmax(logits,axis=1)\r\n",
        "      pred = tf.argmax(prob,axis=1)\r\n",
        "      pred = tf.cast(pred,dtype=tf.int32)\r\n",
        "      correct = tf.equal(pred,y)\r\n",
        "      correct = tf.reduce_sum(tf.cast(correct,dtype=tf.int32))\r\n",
        "\r\n",
        "      total_correct += int(correct)\r\n",
        "      total_num += x.shape[0]\r\n",
        "    acc = total_correct / total_num\r\n",
        "    print(epoch,'test acc:',acc)\r\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 loss= 0.36308419704437256\n",
            "0 100 loss= 0.365620881319046\n",
            "0 200 loss= 0.25550708174705505\n",
            "0 300 loss= 0.2903245985507965\n",
            "0 400 loss= 0.20422053337097168\n",
            "0 test acc: 0.866\n",
            "1 0 loss= 0.37439531087875366\n",
            "1 100 loss= 0.274347722530365\n",
            "1 200 loss= 0.30140048265457153\n",
            "1 300 loss= 0.30662065744400024\n",
            "1 400 loss= 0.26595091819763184\n",
            "1 test acc: 0.8755\n",
            "2 0 loss= 0.339439332485199\n",
            "2 100 loss= 0.28636789321899414\n",
            "2 200 loss= 0.16893523931503296\n",
            "2 300 loss= 0.38000428676605225\n",
            "2 400 loss= 0.3531782627105713\n",
            "2 test acc: 0.8795\n",
            "3 0 loss= 0.21474409103393555\n",
            "3 100 loss= 0.23773255944252014\n",
            "3 200 loss= 0.21199482679367065\n",
            "3 300 loss= 0.3250843584537506\n",
            "3 400 loss= 0.2495397925376892\n",
            "3 test acc: 0.8784\n",
            "4 0 loss= 0.3265400230884552\n",
            "4 100 loss= 0.2805785536766052\n",
            "4 200 loss= 0.3122848868370056\n",
            "4 300 loss= 0.1780899465084076\n",
            "4 400 loss= 0.19995293021202087\n",
            "4 test acc: 0.8857\n",
            "5 0 loss= 0.18080806732177734\n",
            "5 100 loss= 0.2569410800933838\n",
            "5 200 loss= 0.21574077010154724\n",
            "5 300 loss= 0.20262539386749268\n",
            "5 400 loss= 0.25980445742607117\n",
            "5 test acc: 0.8806\n",
            "6 0 loss= 0.1877875030040741\n",
            "6 100 loss= 0.2622344493865967\n",
            "6 200 loss= 0.157321497797966\n",
            "6 300 loss= 0.17422614991664886\n",
            "6 400 loss= 0.24414706230163574\n",
            "6 test acc: 0.8749\n",
            "7 0 loss= 0.21916458010673523\n",
            "7 100 loss= 0.1230626180768013\n",
            "7 200 loss= 0.16686967015266418\n",
            "7 300 loss= 0.22033141553401947\n",
            "7 400 loss= 0.16291765868663788\n",
            "7 test acc: 0.8823\n",
            "8 0 loss= 0.2967146039009094\n",
            "8 100 loss= 0.15299731492996216\n",
            "8 200 loss= 0.23278360068798065\n",
            "8 300 loss= 0.1067277193069458\n",
            "8 400 loss= 0.1714169979095459\n",
            "8 test acc: 0.8874\n",
            "9 0 loss= 0.12054719775915146\n",
            "9 100 loss= 0.1798853576183319\n",
            "9 200 loss= 0.16861900687217712\n",
            "9 300 loss= 0.15906623005867004\n",
            "9 400 loss= 0.23660719394683838\n",
            "9 test acc: 0.8832\n",
            "10 0 loss= 0.2279665470123291\n",
            "10 100 loss= 0.17229920625686646\n",
            "10 200 loss= 0.24481651186943054\n",
            "10 300 loss= 0.15918000042438507\n",
            "10 400 loss= 0.17414309084415436\n",
            "10 test acc: 0.8877\n",
            "11 0 loss= 0.27521568536758423\n",
            "11 100 loss= 0.2373480498790741\n",
            "11 200 loss= 0.17202581465244293\n",
            "11 300 loss= 0.3051965534687042\n",
            "11 400 loss= 0.18208090960979462\n",
            "11 test acc: 0.8883\n",
            "12 0 loss= 0.1137077733874321\n",
            "12 100 loss= 0.15352940559387207\n",
            "12 200 loss= 0.10657189041376114\n",
            "12 300 loss= 0.17734825611114502\n",
            "12 400 loss= 0.1844925880432129\n",
            "12 test acc: 0.8878\n",
            "13 0 loss= 0.09590499848127365\n",
            "13 100 loss= 0.22094273567199707\n",
            "13 200 loss= 0.16975153982639313\n",
            "13 300 loss= 0.19831524789333344\n",
            "13 400 loss= 0.22901412844657898\n",
            "13 test acc: 0.8874\n",
            "14 0 loss= 0.17456895112991333\n",
            "14 100 loss= 0.21765674650669098\n",
            "14 200 loss= 0.20447713136672974\n",
            "14 300 loss= 0.13069984316825867\n",
            "14 400 loss= 0.19124259054660797\n",
            "14 test acc: 0.883\n",
            "15 0 loss= 0.1290372610092163\n",
            "15 100 loss= 0.18318313360214233\n",
            "15 200 loss= 0.19193744659423828\n",
            "15 300 loss= 0.24140609800815582\n",
            "15 400 loss= 0.1815505474805832\n",
            "15 test acc: 0.8867\n",
            "16 0 loss= 0.22124479711055756\n",
            "16 100 loss= 0.15140694379806519\n",
            "16 200 loss= 0.1889984905719757\n",
            "16 300 loss= 0.1739341914653778\n",
            "16 400 loss= 0.23828399181365967\n",
            "16 test acc: 0.8938\n",
            "17 0 loss= 0.2169075459241867\n",
            "17 100 loss= 0.16434895992279053\n",
            "17 200 loss= 0.22315454483032227\n",
            "17 300 loss= 0.2218906581401825\n",
            "17 400 loss= 0.09116034209728241\n",
            "17 test acc: 0.8895\n",
            "18 0 loss= 0.21232205629348755\n",
            "18 100 loss= 0.12488126009702682\n",
            "18 200 loss= 0.11778181046247482\n",
            "18 300 loss= 0.1921607255935669\n",
            "18 400 loss= 0.061229512095451355\n",
            "18 test acc: 0.8877\n",
            "19 0 loss= 0.144832581281662\n",
            "19 100 loss= 0.21317532658576965\n",
            "19 200 loss= 0.19729885458946228\n",
            "19 300 loss= 0.1371937394142151\n",
            "19 400 loss= 0.19445165991783142\n",
            "19 test acc: 0.8833\n",
            "20 0 loss= 0.09757872670888901\n",
            "20 100 loss= 0.15400652587413788\n",
            "20 200 loss= 0.14523136615753174\n",
            "20 300 loss= 0.13757507503032684\n",
            "20 400 loss= 0.11276087909936905\n",
            "20 test acc: 0.8918\n",
            "21 0 loss= 0.1902175396680832\n",
            "21 100 loss= 0.15545153617858887\n",
            "21 200 loss= 0.08829543739557266\n",
            "21 300 loss= 0.09474126994609833\n",
            "21 400 loss= 0.10774242877960205\n",
            "21 test acc: 0.8931\n",
            "22 0 loss= 0.16781780123710632\n",
            "22 100 loss= 0.1071452647447586\n",
            "22 200 loss= 0.13266617059707642\n",
            "22 300 loss= 0.13874845206737518\n",
            "22 400 loss= 0.18298421800136566\n",
            "22 test acc: 0.8911\n",
            "23 0 loss= 0.1833334118127823\n",
            "23 100 loss= 0.08322788774967194\n",
            "23 200 loss= 0.0857403576374054\n",
            "23 300 loss= 0.05744410306215286\n",
            "23 400 loss= 0.1843881905078888\n",
            "23 test acc: 0.8948\n",
            "24 0 loss= 0.09923931956291199\n",
            "24 100 loss= 0.13402950763702393\n",
            "24 200 loss= 0.14389964938163757\n",
            "24 300 loss= 0.16056981682777405\n",
            "24 400 loss= 0.1322224736213684\n",
            "24 test acc: 0.8909\n",
            "25 0 loss= 0.09123994410037994\n",
            "25 100 loss= 0.0894300639629364\n",
            "25 200 loss= 0.1741509735584259\n",
            "25 300 loss= 0.18287238478660583\n",
            "25 400 loss= 0.24801449477672577\n",
            "25 test acc: 0.8901\n",
            "26 0 loss= 0.17025348544120789\n",
            "26 100 loss= 0.1615661382675171\n",
            "26 200 loss= 0.1303483247756958\n",
            "26 300 loss= 0.08097601681947708\n",
            "26 400 loss= 0.15701605379581451\n",
            "26 test acc: 0.8901\n",
            "27 0 loss= 0.17775744199752808\n",
            "27 100 loss= 0.1747756004333496\n",
            "27 200 loss= 0.1510637104511261\n",
            "27 300 loss= 0.10691576451063156\n",
            "27 400 loss= 0.07794040441513062\n",
            "27 test acc: 0.8866\n",
            "28 0 loss= 0.12232200056314468\n",
            "28 100 loss= 0.07423960417509079\n",
            "28 200 loss= 0.11298676580190659\n",
            "28 300 loss= 0.148028165102005\n",
            "28 400 loss= 0.10159110277891159\n",
            "28 test acc: 0.893\n",
            "29 0 loss= 0.10777618736028671\n",
            "29 100 loss= 0.1406681090593338\n",
            "29 200 loss= 0.1564624160528183\n",
            "29 300 loss= 0.11973574757575989\n",
            "29 400 loss= 0.1264011561870575\n",
            "29 test acc: 0.8899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLAW3Pf9Lzaa"
      },
      "source": [
        "可以看到刚开始准确率就能达到0.8以上，对比之前写的三层神经网络，五层神经网络的精度提升是非常明显的"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooiKz165At5Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}